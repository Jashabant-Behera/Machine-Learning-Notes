{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. BANKING & FINANCE\n",
    "\n",
    "### 2.1 Fraud Detection & Prevention\n",
    "\n",
    "**The Challenge:**\n",
    "- Global card fraud: $28 billion annually\n",
    "- Traditional rule-based systems miss 30-40% of fraud\n",
    "- False positives: Blocking legitimate customers hurts revenue\n",
    "\n",
    "**ML Solution: Real-Time Anomaly Detection**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import IsolationForest, RandomForestClassifier\n",
    "\n",
    "class BankingFraudDetector:\n",
    "    def __init__(self):\n",
    "        self.anomaly_detector = IsolationForest(contamination=0.01)\n",
    "        self.classification_model = RandomForestClassifier()\n",
    "        \n",
    "    def assess_transaction_risk(self, transaction):\n",
    "        \"\"\"Evaluate transaction in milliseconds\"\"\"\n",
    "        \n",
    "        # Extract features\n",
    "        features = self.extract_transaction_features(transaction)\n",
    "        \n",
    "        # Method 1: Anomaly Detection\n",
    "        # Is this transaction unusual compared to historical pattern?\n",
    "        anomaly_score = self.anomaly_detector.decision_function([features])[0]\n",
    "        \n",
    "        # Method 2: Classification\n",
    "        # Is this transaction fraudulent based on known patterns?\n",
    "        fraud_prob = self.classification_model.predict_proba([features])[0][1]\n",
    "        \n",
    "        # Combine signals\n",
    "        risk_score = 0.6 * fraud_prob + 0.4 * (1 - anomaly_score)  # 0-1 scale\n",
    "        \n",
    "        # Decision\n",
    "        if risk_score > 0.9:\n",
    "            action = 'BLOCK'\n",
    "            verification = 'DECLINE'\n",
    "        elif risk_score > 0.7:\n",
    "            action = 'CHALLENGE'\n",
    "            verification = 'OTP or 3D Secure'\n",
    "        elif risk_score > 0.5:\n",
    "            action = 'MONITOR'\n",
    "            verification = 'Approve but flag for review'\n",
    "        else:\n",
    "            action = 'APPROVE'\n",
    "            verification = None\n",
    "        \n",
    "        return {\n",
    "            'action': action,\n",
    "            'risk_score': risk_score,\n",
    "            'fraud_probability': fraud_prob,\n",
    "            'anomaly_score': anomaly_score,\n",
    "            'verification_required': verification\n",
    "        }\n",
    "    \n",
    "    def extract_transaction_features(self, txn):\n",
    "        \"\"\"Engineer features to detect fraud\"\"\"\n",
    "        \n",
    "        customer_id = txn['customer_id']\n",
    "        \n",
    "        # Behavioral baseline (what's normal for this customer?)\n",
    "        baseline = self.get_customer_baseline(customer_id)\n",
    "        \n",
    "        features = {\n",
    "            # Amount anomalies\n",
    "            'amount_vs_avg': txn['amount'] / baseline['avg_transaction'],\n",
    "            'amount_vs_max': txn['amount'] / baseline['max_transaction'],\n",
    "            'is_round_amount': txn['amount'] % 100 == 0,  # Round amounts suspicious\n",
    "            \n",
    "            # Location anomalies\n",
    "            'distance_from_home': calculate_distance(\n",
    "                txn['location'],\n",
    "                baseline['home_location']\n",
    "            ),\n",
    "            'time_to_previous': (\n",
    "                txn['timestamp'] - baseline['last_transaction_time']\n",
    "            ).total_seconds() / 3600,  # Hours\n",
    "            'impossible_travel': is_impossible_travel(\n",
    "                baseline['last_location'],\n",
    "                txn['location'],\n",
    "                self.time_to_previous\n",
    "            ),\n",
    "            'new_merchant_mcc': txn['merchant_mcc'] not in baseline['merchant_mccs'],\n",
    "            'new_country': txn['country'] != baseline['home_country'],\n",
    "            'high_risk_country': is_high_risk(txn['country']),\n",
    "            \n",
    "            # Velocity patterns\n",
    "            'transactions_today': count_today_transactions(customer_id),\n",
    "            'transactions_last_hour': count_transactions_last_hour(customer_id),\n",
    "            'failed_attempts_today': count_failed_attempts_today(customer_id),\n",
    "            'unique_merchants_today': count_unique_merchants_today(customer_id),\n",
    "            \n",
    "            # Device & Network\n",
    "            'new_device': txn['device_id'] not in baseline['known_devices'],\n",
    "            'new_ip': txn['ip_address'] not in baseline['known_ips'],\n",
    "            'vpn_detected': is_vpn_or_proxy(txn['ip_address']),\n",
    "            'suspicious_user_agent': is_bot_user_agent(txn['user_agent']),\n",
    "            \n",
    "            # Card characteristics\n",
    "            'card_recently_issued': (\n",
    "                datetime.now() - txn['card_issue_date']\n",
    "            ).days < 30,\n",
    "            'card_about_to_expire': (\n",
    "                datetime.now() - txn['card_expiry']\n",
    "            ).days < 30,\n",
    "            'international_card': is_international_card(txn['card_number']),\n",
    "            'card_brand_unusual': txn['card_brand'] not in baseline['used_brands'],\n",
    "            \n",
    "            # Transaction metadata\n",
    "            'amount_matches_known_fraud': txn['amount'] in known_fraud_amounts,\n",
    "            'mcc_matches_known_fraud': txn['merchant_mcc'] in fraud_prone_mccs,\n",
    "            'cvv_provided': 'cvv' in txn,\n",
    "            'avs_mismatch': txn.get('avs_result') != 'Y',\n",
    "        }\n",
    "        \n",
    "        return np.array(list(features.values()))\n",
    "    \n",
    "    def get_customer_baseline(self, customer_id):\n",
    "        \"\"\"Build customer's normal behavior profile\"\"\"\n",
    "        \n",
    "        # Get last 6 months of transactions\n",
    "        transactions = get_customer_transactions(customer_id, days=180)\n",
    "        \n",
    "        return {\n",
    "            'avg_transaction': np.mean([t['amount'] for t in transactions]),\n",
    "            'max_transaction': np.max([t['amount'] for t in transactions]),\n",
    "            'std_transaction': np.std([t['amount'] for t in transactions]),\n",
    "            'home_location': get_most_common_location(transactions),\n",
    "            'home_country': get_most_common_country(transactions),\n",
    "            'last_transaction_time': transactions[-1]['timestamp'],\n",
    "            'last_location': transactions[-1]['location'],\n",
    "            'merchant_mccs': set(t['merchant_mcc'] for t in transactions),\n",
    "            'known_devices': set(t.get('device_id') for t in transactions),\n",
    "            'known_ips': set(t.get('ip_address') for t in transactions),\n",
    "            'used_brands': set(t['card_brand'] for t in transactions),\n",
    "        }\n",
    "\n",
    "# Real-world performance (Singapore banks):\n",
    "# - 3.5x analyst productivity improvement\n",
    "# - 72% reduction in false positives\n",
    "# - Faster detection of new scam types\n",
    "# - Processed millions of transactions daily\n",
    "\n",
    "# Global impact:\n",
    "# - Fraud detection accuracy: 95-99%\n",
    "# - Response time: <100ms per transaction\n",
    "# - False positive rate: <2% (important for customer satisfaction)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Credit Scoring & Loan Approval\n",
    "\n",
    "**The Challenge:**\n",
    "- Traditional scoring: Biased, inflexible, slow\n",
    "- Miss creditworthy customers (especially new entrants)\n",
    "- Too rigid for modern financial products\n",
    "\n",
    "**ML Solution: Dynamic Credit Scoring**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CreditScoringModel:\n",
    "    def __init__(self):\n",
    "        self.model = GradientBoostingClassifier()\n",
    "    \n",
    "    def predict_default_probability(self, applicant):\n",
    "        \"\"\"Determine probability applicant will default\"\"\"\n",
    "        \n",
    "        features = self.extract_credit_features(applicant)\n",
    "        \n",
    "        # Probability of default (0 = safe, 1 = high risk)\n",
    "        default_prob = self.model.predict_proba([features])[0][1]\n",
    "        \n",
    "        # Convert to credit score (300-850 standard range)\n",
    "        credit_score = 850 - (default_prob * 550)\n",
    "        \n",
    "        # Determine approval and terms\n",
    "        if credit_score >= 750:\n",
    "            decision = 'APPROVED'\n",
    "            interest_rate = 4.5  # Best rate\n",
    "            max_loan = applicant['requested_amount'] * 1.5\n",
    "        elif credit_score >= 700:\n",
    "            decision = 'APPROVED'\n",
    "            interest_rate = 6.5\n",
    "            max_loan = applicant['requested_amount']\n",
    "        elif credit_score >= 650:\n",
    "            decision = 'APPROVED_WITH_CONDITIONS'\n",
    "            interest_rate = 9.0\n",
    "            max_loan = applicant['requested_amount'] * 0.8\n",
    "            conditions = 'Requires co-signer'\n",
    "        else:\n",
    "            decision = 'REJECTED'\n",
    "            interest_rate = None\n",
    "            max_loan = 0\n",
    "        \n",
    "        return {\n",
    "            'credit_score': credit_score,\n",
    "            'default_probability': default_prob,\n",
    "            'decision': decision,\n",
    "            'interest_rate': interest_rate,\n",
    "            'max_loan_amount': max_loan,\n",
    "            'conditions': conditions if 'conditions' in locals() else None\n",
    "        }\n",
    "    \n",
    "    def extract_credit_features(self, applicant):\n",
    "        \"\"\"Engineer comprehensive credit features\"\"\"\n",
    "        \n",
    "        # Traditional features\n",
    "        age = applicant['age']\n",
    "        employment_length = applicant['employment_years']\n",
    "        annual_income = applicant['annual_income']\n",
    "        loan_amount = applicant['requested_amount']\n",
    "        loan_to_income = loan_amount / annual_income\n",
    "        \n",
    "        # Credit history\n",
    "        credit_age = applicant.get('oldest_account_age_years', 0)\n",
    "        total_accounts = applicant.get('total_accounts', 0)\n",
    "        open_accounts = applicant.get('open_accounts', 0)\n",
    "        closed_accounts = applicant.get('closed_accounts', 0)\n",
    "        \n",
    "        # Historical behavior\n",
    "        past_defaults = applicant.get('default_count', 0)\n",
    "        past_late_payments = applicant.get('late_payment_count', 0)\n",
    "        past_inquiries = applicant.get('credit_inquiries_6m', 0)  # Too many = desperate\n",
    "        \n",
    "        # Debt metrics\n",
    "        total_debt = applicant.get('total_debt_outstanding', 0)\n",
    "        debt_to_income = total_debt / annual_income if annual_income > 0 else 1.0\n",
    "        max_credit_utilization = max(\n",
    "            [a['balance'] / a['limit'] for a in applicant.get('accounts', [])]\n",
    "        ) if applicant.get('accounts') else 0\n",
    "        \n",
    "        # Alternative data (for customers with no credit history)\n",
    "        rent_payment_history = applicant.get('rent_paid_on_time', 1.0)  # %\n",
    "        utility_payment_history = applicant.get('utilities_paid_on_time', 1.0)\n",
    "        phone_payment_history = applicant.get('phone_paid_on_time', 1.0)\n",
    "        \n",
    "        # Employment stability\n",
    "        job_stability_score = calculate_stability(\n",
    "            applicant['employment_history']\n",
    "        )\n",
    "        industry_risk = get_industry_default_rate(applicant['industry'])\n",
    "        \n",
    "        # Demographics (careful: avoid discrimination)\n",
    "        # Can use: education, occupation (not protected)\n",
    "        # Cannot use: race, gender, age (in most jurisdictions)\n",
    "        education_level = encode_education(applicant.get('education'))\n",
    "        has_college_degree = 1 if applicant.get('education') == 'bachelor+' else 0\n",
    "        \n",
    "        return np.array([\n",
    "            age,\n",
    "            employment_length,\n",
    "            annual_income,\n",
    "            loan_to_income,\n",
    "            credit_age,\n",
    "            total_accounts,\n",
    "            open_accounts,\n",
    "            closed_accounts,\n",
    "            past_defaults,\n",
    "            past_late_payments,\n",
    "            past_inquiries,\n",
    "            total_debt,\n",
    "            debt_to_income,\n",
    "            max_credit_utilization,\n",
    "            rent_payment_history,\n",
    "            utility_payment_history,\n",
    "            phone_payment_history,\n",
    "            job_stability_score,\n",
    "            industry_risk,\n",
    "            education_level,\n",
    "            has_college_degree\n",
    "        ])\n",
    "\n",
    "# Real-world impact:\n",
    "# - Loan approval speed: 5 minutes (vs 5 days traditional)\n",
    "# - Default rate: 2-4% (improved prediction)\n",
    "# - Expanded customer base: +30-50% (reach underbanked)\n",
    "# - Cost savings: Automation reduces processing cost 80%\n",
    "\n",
    "# Alternative credit data:\n",
    "# - Some banks now use mobile payment history\n",
    "# - Rental payment history\n",
    "# - Utility payment history\n",
    "# - Gig economy income\n",
    "# - To serve customers without traditional credit history\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Stock Market Prediction & Portfolio Management\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PortfolioOptimizer:\n",
    "    def __init__(self):\n",
    "        self.model = LSTM()  # Time series deep learning\n",
    "        \n",
    "    def predict_returns(self, stock_symbol, horizon_days=30):\n",
    "        \"\"\"Forecast stock returns\"\"\"\n",
    "        \n",
    "        # Get historical data\n",
    "        prices = get_historical_prices(stock_symbol, days=252)  # 1 year\n",
    "        \n",
    "        # Predict future returns\n",
    "        features = self.create_timeseries_features(prices)\n",
    "        predictions = self.model.predict(features)\n",
    "        \n",
    "        return predictions\n",
    "    \n",
    "    def optimize_portfolio(self, available_stocks, investment_amount):\n",
    "        \"\"\"Allocate funds across stocks to maximize returns/minimize risk\"\"\"\n",
    "        \n",
    "        # Get predictions for all stocks\n",
    "        returns = {}\n",
    "        volatilities = {}\n",
    "        \n",
    "        for stock in available_stocks:\n",
    "            returns[stock] = self.predict_returns(stock)\n",
    "            volatilities[stock] = calculate_volatility(stock)\n",
    "        \n",
    "        # Modern Portfolio Theory: Maximize Sharpe Ratio\n",
    "        # Sharpe = (Expected Return - Risk Free Rate) / Volatility\n",
    "        \n",
    "        # Efficient frontier: Find optimal allocation\n",
    "        correlations = calculate_correlation_matrix(available_stocks)\n",
    "        \n",
    "        optimal_allocation = minimize(\n",
    "            objective=lambda w: -sharpe_ratio(w, returns, volatilities, correlations),\n",
    "            weights_sum=1.0,\n",
    "            bounds=(0, 1)  # No short selling\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'allocation': optimal_allocation,\n",
    "            'expected_return': calculate_portfolio_return(optimal_allocation, returns),\n",
    "            'expected_volatility': calculate_portfolio_volatility(\n",
    "                optimal_allocation, volatilities, correlations\n",
    "            ),\n",
    "            'sharpe_ratio': calculate_sharpe_ratio(...)\n",
    "        }\n",
    "\n",
    "# Real-world: Robo-advisors use this to manage trillions\n",
    "# - Vanguard Personal Advisor Services\n",
    "# - Wealthfront, Betterment (automated portfolio management)\n",
    "# - Goldman Sachs: Replaced 600 stock traders with ML system (2017)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}