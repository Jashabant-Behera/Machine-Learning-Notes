{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Real-World Applications Across Industries\n",
    "\n",
    "**Author:** ML Applications Series  \n",
    "**Topic:** Practical Use Cases in Business & Industry  \n",
    "**Level:** Intermediate Learner\n",
    "\n",
    "---\n",
    "\n",
    "## Table of Contents\n",
    "1. Retail & E-Commerce (Amazon, Big Bazaar)\n",
    "2. Banking & Finance\n",
    "3. Healthcare & Pharmaceuticals\n",
    "4. Transportation & Logistics\n",
    "5. Manufacturing\n",
    "6. Consumer Internet & Social Media (Twitter/X)\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. RETAIL & E-COMMERCE\n",
    "\n",
    "### Industry Overview\n",
    "Global e-commerce market: $5.8 trillion (2023), growing 10% annually\n",
    "\n",
    "### 1.1 Personalized Recommendations\n",
    "\n",
    "**The Problem:**\n",
    "- Amazon alone has 300+ million products\n",
    "- Without recommendations, customers overwhelmed\n",
    "- Random product suggestions = lost sales\n",
    "\n",
    "**The Solution: Recommendation Engines**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How Amazon's recommendation system works\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "class AmazonRecommender:\n",
    "    def __init__(self):\n",
    "        self.user_item_matrix = None  # m x n matrix (users x items)\n",
    "        self.user_profiles = {}\n",
    "        \n",
    "    def collect_signals(self, user_id):\n",
    "        \"\"\"Gather all user behavior signals\"\"\"\n",
    "        signals = {\n",
    "            'purchase_history': get_purchases(user_id),      # What they bought\n",
    "            'browse_history': get_browsing(user_id),          # What they looked at\n",
    "            'wishlist': get_wishlist(user_id),                # What they saved\n",
    "            'ratings': get_ratings(user_id),                  # What they rated\n",
    "            'time_spent': get_view_time(user_id),             # Time viewing products\n",
    "            'device_info': get_device(user_id),               # Desktop vs mobile\n",
    "            'location': get_location(user_id),                # Geographic data\n",
    "            'demographics': get_demographics(user_id),        # Age, gender\n",
    "        }\n",
    "        return signals\n",
    "    \n",
    "    def compute_recommendations(self, user_id, top_k=10):\n",
    "        \"\"\"Generate personalized product recommendations\"\"\"\n",
    "        \n",
    "        # Step 1: Get user profile (what they like)\n",
    "        user_signals = self.collect_signals(user_id)\n",
    "        \n",
    "        # Step 2: Collaborative Filtering\n",
    "        # Find similar users (people with similar taste)\n",
    "        similar_users = self.find_similar_users(user_id)\n",
    "        \n",
    "        # Step 3: Get products from similar users\n",
    "        candidate_products = set()\n",
    "        for similar_user in similar_users:\n",
    "            candidate_products.update(\n",
    "                get_purchases(similar_user)\n",
    "            )\n",
    "        \n",
    "        # Remove products user already bought\n",
    "        candidate_products -= set(user_signals['purchase_history'])\n",
    "        \n",
    "        # Step 4: Content-Based Filtering\n",
    "        # Find products similar to what user liked\n",
    "        liked_products = user_signals['purchase_history']\n",
    "        content_similar = []\n",
    "        \n",
    "        for candidate in candidate_products:\n",
    "            similarity = compute_product_similarity(\n",
    "                liked_products,\n",
    "                candidate\n",
    "            )\n",
    "            content_similar.append((candidate, similarity))\n",
    "        \n",
    "        # Step 5: Rank and filter\n",
    "        ranked = sorted(content_similar, key=lambda x: x[1], reverse=True)\n",
    "        recommendations = [p[0] for p in ranked[:top_k]]\n",
    "        \n",
    "        return recommendations\n",
    "    \n",
    "    def find_similar_users(self, user_id):\n",
    "        \"\"\"Find users with similar purchase patterns\"\"\"\n",
    "        from sklearn.metrics.pairwise import cosine_similarity\n",
    "        \n",
    "        user_vector = self.user_item_matrix[user_id]\n",
    "        similarities = cosine_similarity([user_vector], self.user_item_matrix)[0]\n",
    "        \n",
    "        # Get top similar users\n",
    "        similar_indices = np.argsort(similarities)[-10:]\n",
    "        return similar_indices\n",
    "\n",
    "# Real-world metrics:\n",
    "# - Amazon: 35% of revenue from recommendations\n",
    "# - Netflix: 80% of watch time from recommendations  \n",
    "# - Target: 15% of sales from personalization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Impact:**\n",
    "- Revenue increase: +30-40%\n",
    "- Average order value: +20-25%\n",
    "- Customer retention: +15-20%\n",
    "\n",
    "### 1.2 Dynamic Pricing\n",
    "\n",
    "**The Problem:**\n",
    "Traditional pricing: Fixed prices that don't respond to market\n",
    "- Miss revenue opportunities\n",
    "- Lose sales during high-demand periods\n",
    "- Overprice during low-demand periods\n",
    "\n",
    "**The Solution: ML-Powered Dynamic Pricing**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DynamicPricingEngine:\n",
    "    def __init__(self):\n",
    "        self.price_model = None\n",
    "    \n",
    "    def calculate_optimal_price(self, product_id, context):\n",
    "        \"\"\"Determine ideal price in real-time\"\"\"\n",
    "        \n",
    "        # Collect contextual data\n",
    "        demand_signals = {\n",
    "            'current_inventory': context['inventory'],       # Low stock \u2192 raise price\n",
    "            'competitor_prices': context['competitor_price'], # Undercut if needed\n",
    "            'seasonal_demand': context['season'],             # Holiday \u2192 raise price\n",
    "            'customer_segment': context['customer_type'],     # Premium \u2192 higher price\n",
    "            'time_of_day': context['time'],                   # Peak hours \u2192 higher\n",
    "            'day_of_week': context['weekday'],                # Weekend \u2192 higher\n",
    "            'weather': context['weather'],                    # Cold \u2192 raise AC prices\n",
    "            'search_trends': context['search_volume'],        # High searches \u2192 raise\n",
    "            'browsing_speed': context['add_to_cart_rate'],    # Fast \u2192 higher elasticity\n",
    "        }\n",
    "        \n",
    "        # Historical data: What prices worked before?\n",
    "        historical_data = get_historical_pricing_data(product_id)\n",
    "        \n",
    "        # ML model: Predict optimal price\n",
    "        features = vectorize_context(demand_signals)\n",
    "        predicted_elasticity = self.elasticity_model.predict([features])[0]\n",
    "        \n",
    "        # Price optimization: Maximize revenue = Price \u00d7 Quantity\n",
    "        # revenue(p) = p \u00d7 (demand_function(p))\n",
    "        optimal_price = optimize_for_max_revenue(\n",
    "            predicted_elasticity,\n",
    "            current_price=context['current_price'],\n",
    "            min_price=context['min_price'],\n",
    "            max_price=context['max_price']\n",
    "        )\n",
    "        \n",
    "        return optimal_price\n",
    "\n",
    "# Real-world examples:\n",
    "# Amazon: Prices change 10M+ times daily for different products\n",
    "# Uber: Surge pricing during peak demand\n",
    "# Airbnb: Dynamic pricing based on demand, seasonality, events\n",
    "# Target: Personalized prices for different customer segments\n",
    "\n",
    "# Impact:\n",
    "# - Revenue increase: 5-15%\n",
    "# - Margin improvement: 2-5%\n",
    "# - Inventory turnover: +20-30% (faster moving stock)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Demand Forecasting & Inventory Optimization\n",
    "\n",
    "**The Problem:**\n",
    "- Too much inventory: Waste money on storage, markdowns\n",
    "- Too little inventory: Lost sales, customer frustration\n",
    "- Seasonal variations: Hard to predict\n",
    "\n",
    "**The Solution: Predictive Demand Forecasting**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "class InventoryOptimizer:\n",
    "    def __init__(self):\n",
    "        self.demand_model = RandomForestRegressor(n_estimators=100)\n",
    "        \n",
    "    def forecast_demand(self, product_id, next_n_days=30):\n",
    "        \"\"\"Predict demand for next 30 days\"\"\"\n",
    "        \n",
    "        # Historical data\n",
    "        historical = pd.read_csv(f'sales_{product_id}.csv')\n",
    "        \n",
    "        # Features for prediction\n",
    "        X = self.create_features(historical)\n",
    "        y = historical['units_sold']\n",
    "        \n",
    "        # Train model\n",
    "        self.demand_model.fit(X, y)\n",
    "        \n",
    "        # Future features\n",
    "        future_dates = pd.date_range(\n",
    "            start=historical['date'].max(),\n",
    "            periods=next_n_days,\n",
    "            freq='D'\n",
    "        )\n",
    "        \n",
    "        X_future = self.create_features_for_dates(future_dates)\n",
    "        forecast = self.demand_model.predict(X_future)\n",
    "        \n",
    "        return forecast\n",
    "    \n",
    "    def create_features(self, data):\n",
    "        \"\"\"Engineer features for demand prediction\"\"\"\n",
    "        features = pd.DataFrame()\n",
    "        \n",
    "        # Temporal features\n",
    "        features['day_of_week'] = data['date'].dt.dayofweek\n",
    "        features['month'] = data['date'].dt.month\n",
    "        features['day_of_month'] = data['date'].dt.day\n",
    "        features['quarter'] = data['date'].dt.quarter\n",
    "        features['is_holiday'] = is_holiday(data['date'])\n",
    "        \n",
    "        # Lag features (past sales)\n",
    "        features['sales_lag_1'] = data['units_sold'].shift(1)\n",
    "        features['sales_lag_7'] = data['units_sold'].shift(7)\n",
    "        features['sales_lag_30'] = data['units_sold'].shift(30)\n",
    "        \n",
    "        # Rolling averages\n",
    "        features['sales_ma_7'] = data['units_sold'].rolling(7).mean()\n",
    "        features['sales_ma_30'] = data['units_sold'].rolling(30).mean()\n",
    "        \n",
    "        # External signals\n",
    "        features['competitor_price'] = data['competitor_price']\n",
    "        features['our_price'] = data['our_price']\n",
    "        features['promotion_active'] = data['has_promotion']\n",
    "        features['website_traffic'] = data['traffic']\n",
    "        \n",
    "        return features.fillna(0)\n",
    "    \n",
    "    def optimize_inventory(self, product_id, safety_stock=20):\n",
    "        \"\"\"Determine optimal inventory level\"\"\"\n",
    "        \n",
    "        # Forecast demand\n",
    "        forecast = self.forecast_demand(product_id, next_n_days=30)\n",
    "        \n",
    "        # Calculate statistics\n",
    "        expected_demand = np.mean(forecast)\n",
    "        demand_std = np.std(forecast)\n",
    "        demand_variance = demand_std ** 2\n",
    "        \n",
    "        # Lead time (how long to get new stock)\n",
    "        lead_time = get_lead_time(product_id)  # e.g., 7 days\n",
    "        \n",
    "        # Optimal stock calculation\n",
    "        # EOQ (Economic Order Quantity) = sqrt((2 * D * S) / H)\n",
    "        # D = annual demand\n",
    "        # S = order cost\n",
    "        # H = holding cost\n",
    "        \n",
    "        annual_demand = np.sum(forecast) * 12  # Extrapolate to year\n",
    "        order_cost = get_order_cost(product_id)\n",
    "        holding_cost = get_holding_cost(product_id)\n",
    "        \n",
    "        eoq = np.sqrt((2 * annual_demand * order_cost) / holding_cost)\n",
    "        \n",
    "        # Safety stock to avoid stockouts\n",
    "        # Assuming normal distribution of demand\n",
    "        z_score = 1.96  # 95% confidence\n",
    "        safety_stock_calc = z_score * demand_std * np.sqrt(lead_time)\n",
    "        \n",
    "        # Reorder point = (Average demand per day) \u00d7 Lead time + Safety stock\n",
    "        avg_daily_demand = expected_demand\n",
    "        reorder_point = (avg_daily_demand * lead_time) + safety_stock_calc\n",
    "        \n",
    "        return {\n",
    "            'optimal_order_quantity': eoq,\n",
    "            'reorder_point': reorder_point,\n",
    "            'safety_stock': safety_stock_calc,\n",
    "            'forecasted_demand': expected_demand,\n",
    "            'confidence_interval': (\n",
    "                expected_demand - 1.96 * demand_std,\n",
    "                expected_demand + 1.96 * demand_std\n",
    "            )\n",
    "        }\n",
    "\n",
    "# Real-world impact (Retail):\n",
    "# - Inventory holding costs: -15-30%\n",
    "# - Stockout rate: Reduced 20-40%\n",
    "# - Markdown/waste: Reduced 10-20%\n",
    "# - Cash flow: Improved 25-35%\n",
    "\n",
    "# Walmart's impact:\n",
    "# - Serves 200M+ customers weekly\n",
    "# - Uses ML to forecast demand down to individual stores\n",
    "# - Reduced waste by $1B+ annually\n",
    "# - Improved freshness of products\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Customer Churn Prediction\n",
    "\n",
    "**The Problem:**\n",
    "- Customers leave without warning\n",
    "- Cost to acquire new customer: 5-25x cost to retain\n",
    "- Need to identify at-risk customers BEFORE they leave\n",
    "\n",
    "**The Solution: Churn Prediction Model**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "class ChurnPredictor:\n",
    "    def __init__(self):\n",
    "        self.model = GradientBoostingClassifier()\n",
    "    \n",
    "    def predict_churn_risk(self, customer_id):\n",
    "        \"\"\"Predict probability customer will churn\"\"\"\n",
    "        \n",
    "        # Collect customer features\n",
    "        features = self.extract_features(customer_id)\n",
    "        \n",
    "        # Predict churn probability\n",
    "        churn_prob = self.model.predict_proba([features])[0][1]\n",
    "        \n",
    "        if churn_prob > 0.5:  # High risk\n",
    "            # Recommend retention action\n",
    "            action = self.recommend_retention(customer_id, churn_prob)\n",
    "            return {\n",
    "                'risk': churn_prob,\n",
    "                'action': action,\n",
    "                'incentive': calculate_incentive(churn_prob)\n",
    "            }\n",
    "        \n",
    "        return {'risk': churn_prob, 'action': None}\n",
    "    \n",
    "    def extract_features(self, customer_id):\n",
    "        \"\"\"Engineer features to predict churn\"\"\"\n",
    "        \n",
    "        # Behavioral features\n",
    "        days_as_customer = get_days_since_signup(customer_id)\n",
    "        purchase_frequency = get_purchases_per_month(customer_id)\n",
    "        days_since_last_purchase = get_days_since_purchase(customer_id)\n",
    "        lifetime_value = get_total_spent(customer_id)\n",
    "        avg_order_value = get_avg_order_value(customer_id)\n",
    "        \n",
    "        # Engagement features\n",
    "        login_frequency = get_logins_per_month(customer_id)\n",
    "        app_usage_minutes = get_app_time(customer_id)\n",
    "        reviews_written = get_reviews_count(customer_id)\n",
    "        wishlist_items = get_wishlist_size(customer_id)\n",
    "        \n",
    "        # Support interaction features\n",
    "        support_tickets = get_support_tickets(customer_id)\n",
    "        complaint_count = get_complaints(customer_id)\n",
    "        satisfaction_score = get_satisfaction_rating(customer_id)\n",
    "        \n",
    "        # Competitive exposure\n",
    "        browsed_competitor_sites = did_visit_competitor(customer_id)\n",
    "        price_sensitivity = analyze_price_changes_response(customer_id)\n",
    "        \n",
    "        # Recent patterns\n",
    "        purchase_trend = linear_regression_slope(  # Is spending going up/down?\n",
    "            get_monthly_spend_trend(customer_id)\n",
    "        )\n",
    "        engagement_trend = linear_regression_slope(\n",
    "            get_monthly_engagement_trend(customer_id)\n",
    "        )\n",
    "        \n",
    "        return np.array([\n",
    "            days_as_customer,\n",
    "            purchase_frequency,\n",
    "            days_since_last_purchase,\n",
    "            lifetime_value,\n",
    "            avg_order_value,\n",
    "            login_frequency,\n",
    "            app_usage_minutes,\n",
    "            reviews_written,\n",
    "            wishlist_items,\n",
    "            support_tickets,\n",
    "            complaint_count,\n",
    "            satisfaction_score,\n",
    "            browsed_competitor_sites,\n",
    "            price_sensitivity,\n",
    "            purchase_trend,\n",
    "            engagement_trend\n",
    "        ])\n",
    "    \n",
    "    def recommend_retention(self, customer_id, churn_prob):\n",
    "        \"\"\"Recommend action to retain customer\"\"\"\n",
    "        \n",
    "        if churn_prob > 0.8:  # Very high risk\n",
    "            return {\n",
    "                'action': 'Personal outreach',\n",
    "                'channel': 'Call/Email from manager',\n",
    "                'incentive': '20% discount + free shipping',\n",
    "                'timing': 'Immediate'\n",
    "            }\n",
    "        elif churn_prob > 0.6:  # High risk\n",
    "            return {\n",
    "                'action': 'Special offer',\n",
    "                'channel': 'Email/SMS',\n",
    "                'incentive': '15% discount',\n",
    "                'timing': 'Within 24 hours'\n",
    "            }\n",
    "        elif churn_prob > 0.5:  # Medium risk\n",
    "            return {\n",
    "                'action': 'Personalized recommendation',\n",
    "                'channel': 'Email',\n",
    "                'incentive': '10% discount',\n",
    "                'timing': 'Within 48 hours'\n",
    "            }\n",
    "\n",
    "# Real-world impact (E-commerce):\n",
    "# - Retention improvement: +5-15%\n",
    "# - Revenue impact: +$100K-$1M annually\n",
    "# - Cost of retention: $1-10 per customer\n",
    "# - ROI: 10-100x\n",
    "\n",
    "# Amazon's example:\n",
    "# - Tracks 50+ engagement metrics per customer\n",
    "# - Identifies churning customers 1-2 months early\n",
    "# - Saves $100M+ annually through targeted retention\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 Fraud Detection in E-Commerce\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EcommerceFraudDetector:\n",
    "    def __init__(self):\n",
    "        self.model = RandomForestClassifier()\n",
    "        \n",
    "    def detect_fraudulent_order(self, order):\n",
    "        \"\"\"Identify suspicious orders in real-time\"\"\"\n",
    "        \n",
    "        features = self.extract_features(order)\n",
    "        fraud_prob = self.model.predict_proba([features])[0][1]\n",
    "        \n",
    "        if fraud_prob > 0.7:\n",
    "            # Block or challenge transaction\n",
    "            return {\n",
    "                'status': 'FRAUD_DETECTED',\n",
    "                'action': 'BLOCK' if fraud_prob > 0.9 else 'CHALLENGE',\n",
    "                'confidence': fraud_prob\n",
    "            }\n",
    "        \n",
    "        return {'status': 'APPROVED', 'confidence': fraud_prob}\n",
    "    \n",
    "    def extract_features(self, order):\n",
    "        \"\"\"Detect fraud signals\"\"\"\n",
    "        \n",
    "        # Address verification\n",
    "        billing_shipping_match = order['billing_zip'] == order['shipping_zip']\n",
    "        shipping_country_match = order['billing_country'] == order['shipping_country']\n",
    "        unusual_destination = is_high_risk_country(order['shipping_country'])\n",
    "        \n",
    "        # Purchase pattern anomalies\n",
    "        is_bulk_purchase = order['quantity'] > customer_avg_quantity(order['customer_id']) * 3\n",
    "        order_amount_unusual = (\n",
    "            order['total'] > customer_avg_order(order['customer_id']) * 5\n",
    "        )\n",
    "        multiple_declined = count_declined_cards_recent(order['customer_id']) > 3\n",
    "        \n",
    "        # Device & network signals\n",
    "        new_device = is_new_device(order['customer_id'], order['device_id'])\n",
    "        new_ip = is_new_ip(order['customer_id'], order['ip_address'])\n",
    "        vpn_proxy = is_vpn_or_proxy(order['ip_address'])\n",
    "        \n",
    "        # Velocity checks (too many orders too fast)\n",
    "        orders_last_hour = count_orders_by_customer_past_hour(order['customer_id'])\n",
    "        orders_last_day = count_orders_by_customer_past_day(order['customer_id'])\n",
    "        \n",
    "        # Card characteristics\n",
    "        card_age_days = (datetime.now() - order['card_first_use']).days\n",
    "        card_matches_name = fuzzy_match(order['card_name'], order['customer_name']) > 0.8\n",
    "        card_country = get_card_issuing_country(order['card_number'])\n",
    "        country_mismatch = card_country != order['billing_country']\n",
    "        \n",
    "        # Product risk\n",
    "        high_value_items = any(item['price'] > 1000 for item in order['items'])\n",
    "        electronics_only = all(item['category'] == 'electronics' for item in order['items'])\n",
    "        gift_cards = any(item['product_id'].startswith('gc_') for item in order['items'])\n",
    "        \n",
    "        return np.array([\n",
    "            billing_shipping_match,\n",
    "            shipping_country_match,\n",
    "            unusual_destination,\n",
    "            is_bulk_purchase,\n",
    "            order_amount_unusual,\n",
    "            multiple_declined,\n",
    "            new_device,\n",
    "            new_ip,\n",
    "            vpn_proxy,\n",
    "            orders_last_hour,\n",
    "            orders_last_day,\n",
    "            card_age_days,\n",
    "            card_matches_name,\n",
    "            country_mismatch,\n",
    "            high_value_items,\n",
    "            electronics_only,\n",
    "            gift_cards\n",
    "        ])\n",
    "\n",
    "# Real-world impact:\n",
    "# - Fraud loss reduction: 50-70%\n",
    "# - False positive rate: <1%\n",
    "# - Chargeback reduction: 30-50%\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}