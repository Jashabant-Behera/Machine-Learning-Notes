{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Online Learning\n",
    "\n",
    "### Definition\n",
    "**Online Learning** trains models **incrementally**, updating parameters as new data arrives **one sample or small batch at a time**. The model continuously evolves and adapts to new information.\n",
    "\n",
    "### How It Works\n",
    "\n",
    "```\n",
    "[Sample 1] \u2192 [Model Update 1]\n",
    "                     \u2193\n",
    "[Sample 2] \u2192 [Model Update 2]\n",
    "                     \u2193\n",
    "[Sample 3] \u2192 [Model Update 3]\n",
    "                     \u2193\n",
    "         ... continuous updates ...\n",
    "                     \u2193\n",
    "[Real-time Predictions]\n",
    "```\n",
    "\n",
    "Each new data point immediately affects model parameters.\n",
    "\n",
    "### Characteristics\n",
    "\n",
    "1. **Streaming Data:** Processes data as it arrives\n",
    "2. **Incremental Updates:** Updates model for each sample or mini-batch\n",
    "3. **Memory Efficient:** Only keeps current batch in memory\n",
    "4. **Adaptive:** Quickly responds to data changes\n",
    "5. **Real-time Ready:** Can make predictions immediately\n",
    "6. **Continuous Learning:** Model never \"finished\" - always improving\n",
    "\n",
    "### Advantages of Online Learning\n",
    "\n",
    "#### 1. **Efficiency** \ud83d\ude80\n",
    "- **Memory:** Only one sample/batch in memory at a time\n",
    "- **Computation:** Less resource-intensive than batch learning\n",
    "- **Storage:** Don't need to store entire dataset\n",
    "- **Cost:** Can run on modest hardware (even Raspberry Pi)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Memory-efficient streaming\n",
    "import numpy as np\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "# Instead of loading 1 million samples at once\n",
    "# Process them in mini-batches of 1000\n",
    "\n",
    "model = SGDClassifier(loss='log', random_state=42)\n",
    "\n",
    "total_samples = 1_000_000\n",
    "batch_size = 1_000\n",
    "\n",
    "for i in range(0, total_samples, batch_size):\n",
    "    # Generate mini-batch (in real scenario, stream from source)\n",
    "    X_batch = np.random.rand(batch_size, 100)\n",
    "    y_batch = np.random.randint(0, 2, batch_size)\n",
    "    \n",
    "    # Update model with current batch only\n",
    "    if i == 0:\n",
    "        model.partial_fit(X_batch, y_batch, classes=[0, 1])\n",
    "    else:\n",
    "        model.partial_fit(X_batch, y_batch)\n",
    "    \n",
    "    if i % 100_000 == 0:\n",
    "        print(f\"Processed {i:,} samples, Memory efficient!\")\n",
    "\n",
    "# Same model trained on 1M samples without loading all at once\n",
    "accuracy = model.score(X_batch, y_batch)\n",
    "print(f\"Final accuracy: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. **Adaptability** \ud83d\udd04\n",
    "- Quickly responds to new patterns and concept drift\n",
    "- Learns immediately when market conditions change\n",
    "- Can detect anomalies in real-time\n",
    "- Stays current without waiting for retraining\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Adapting to concept drift\n",
    "from sklearn.datasets import make_classification\n",
    "import numpy as np\n",
    "\n",
    "# Simulate concept drift: data distribution changes over time\n",
    "X_train = []\n",
    "y_train = []\n",
    "\n",
    "model = SGDClassifier(loss='log', warm_start=False)\n",
    "\n",
    "# Phase 1: Initial data distribution\n",
    "for t in range(100):\n",
    "    X_t = np.random.rand(50, 20)\n",
    "    y_t = (X_t[:, 0] > 0.5).astype(int)  # Rule: feature 0 > 0.5\n",
    "    \n",
    "    if t == 0:\n",
    "        model.partial_fit(X_t, y_t, classes=[0, 1])\n",
    "    else:\n",
    "        model.partial_fit(X_t, y_t)\n",
    "\n",
    "accuracy_phase1 = model.score(X_t, y_t)\n",
    "print(f\"Phase 1 Accuracy: {accuracy_phase1:.4f}\")\n",
    "\n",
    "# Phase 2: Concept drift - rules change\n",
    "for t in range(100, 200):\n",
    "    X_t = np.random.rand(50, 20)\n",
    "    # NEW RULE: feature 1 > 0.5 (completely different!)\n",
    "    y_t = (X_t[:, 1] > 0.5).astype(int)\n",
    "    \n",
    "    # Model adapts immediately to new pattern\n",
    "    model.partial_fit(X_t, y_t)\n",
    "\n",
    "accuracy_phase2 = model.score(X_t, y_t)\n",
    "print(f\"Phase 2 Accuracy: {accuracy_phase2:.4f} (adapted to new rule)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. **Real-time Performance** \u26a1\n",
    "- Minimal latency between data and predictions\n",
    "- Suitable for mission-critical applications\n",
    "- Can respond to immediate opportunities/threats\n",
    "- Predictions always based on latest data\n",
    "\n",
    "Real-world example:\n",
    "```\n",
    "Stock Trading:\n",
    "- Online ML: Model learns new market pattern in milliseconds\n",
    "- Makes adjusted trading decision immediately\n",
    "- Captures gains before others notice the pattern\n",
    "\n",
    "Fraud Detection:\n",
    "- Online ML: New fraud pattern detected in real-time\n",
    "- Transaction blocked immediately\n",
    "- Prevents financial loss\n",
    "\n",
    "Recommendation:\n",
    "- Online ML: User clicks on product\n",
    "- Model instantly learns preference\n",
    "- Next recommendation reflects this immediate interest\n",
    "```\n",
    "\n",
    "#### 4. **No Retraining Needed**\n",
    "- Model updates continuously\n",
    "- Never need full retraining from scratch\n",
    "- Faster adaptation compared to batch retraining\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare: Batch vs Online for new data\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "import time\n",
    "\n",
    "# Batch approach\n",
    "X_initial = np.random.rand(100_000, 50)\n",
    "y_initial = np.random.randint(0, 2, 100_000)\n",
    "\n",
    "batch_model = RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "start = time.time()\n",
    "batch_model.fit(X_initial, y_initial)  # Initial training: slow\n",
    "initial_time = time.time() - start\n",
    "print(f\"Batch: Initial training time: {initial_time:.2f}s\")\n",
    "\n",
    "# New data arrives\n",
    "X_new = np.random.rand(10_000, 50)\n",
    "y_new = np.random.randint(0, 2, 10_000)\n",
    "\n",
    "start = time.time()\n",
    "# Must retrain on ALL data again!\n",
    "batch_model.fit(np.vstack([X_initial, X_new]), \n",
    "                np.hstack([y_initial, y_new]))\n",
    "retrain_time = time.time() - start\n",
    "print(f\"Batch: Retraining time: {retrain_time:.2f}s\")\n",
    "\n",
    "# Online approach\n",
    "online_model = SGDClassifier(n_estimators=100)\n",
    "\n",
    "start = time.time()\n",
    "online_model.fit(X_initial, y_initial)\n",
    "online_initial_time = time.time() - start\n",
    "print(f\"\\nOnline: Initial training time: {online_initial_time:.2f}s\")\n",
    "\n",
    "start = time.time()\n",
    "# Just update with new data!\n",
    "online_model.partial_fit(X_new, y_new)\n",
    "update_time = time.time() - start\n",
    "print(f\"Online: Update time: {update_time:.4f}s (much faster!)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### When to Use Online Learning\n",
    "\n",
    "#### 1. **Streaming Data**\n",
    "- Financial data (stock prices, transactions)\n",
    "- Sensor data (IoT devices, weather stations)\n",
    "- Social media feeds\n",
    "- Website analytics\n",
    "- Network traffic monitoring\n",
    "\n",
    "#### 2. **Real-time Applications**\n",
    "- Fraud detection in financial transactions\n",
    "- Spam email filtering (learns new spam patterns instantly)\n",
    "- Recommendation systems (learns user preferences immediately)\n",
    "- Anomaly detection in network security\n",
    "- Self-driving cars (adapt to road conditions in real-time)\n",
    "\n",
    "#### 3. **Concept Drift Scenarios**\n",
    "- Where data patterns change over time\n",
    "- Fashion trends evolving\n",
    "- User behavior changing with seasons\n",
    "- Market conditions shifting\n",
    "- Disease patterns evolving\n",
    "\n",
    "#### 4. **Memory Constraints**\n",
    "- Limited RAM available\n",
    "- Processing on edge devices\n",
    "- Mobile applications\n",
    "- Embedded systems\n",
    "- IoT applications on Raspberry Pi\n",
    "\n",
    "#### 5. **Data at Scale**\n",
    "- Millions of samples arriving daily\n",
    "- Cannot store complete history\n",
    "- Need models that handle infinite data streams\n",
    "- Storage costs prohibitive\n",
    "\n",
    "### Disadvantages of Online Learning\n",
    "\n",
    "#### 1. **Complexity in Implementation** \ud83d\udd34\n",
    "- Requires handling continuous data streams\n",
    "- Managing state and incremental updates complex\n",
    "- Error handling more involved\n",
    "- Harder to debug (data constantly changing)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Complexity of managing streaming state\n",
    "class OnlineLearningPipeline:\n",
    "    def __init__(self):\n",
    "        self.model = SGDClassifier(loss='log', warm_start=False)\n",
    "        self.scaler = StandardScaler()\n",
    "        self.feature_stats = None  # Must track statistics!\n",
    "        self.model_version = 0\n",
    "        self.training_samples = 0\n",
    "        \n",
    "    def process_stream(self, X_batch, y_batch):\n",
    "        \"\"\"\n",
    "        Handle streaming data with proper state management\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Update feature statistics\n",
    "            if self.feature_stats is None:\n",
    "                self.feature_stats = {\n",
    "                    'mean': X_batch.mean(axis=0),\n",
    "                    'std': X_batch.std(axis=0)\n",
    "                }\n",
    "            else:\n",
    "                # Incrementally update statistics (complex!)\n",
    "                alpha = 0.95  # smoothing factor\n",
    "                self.feature_stats['mean'] = (\n",
    "                    alpha * self.feature_stats['mean'] + \n",
    "                    (1-alpha) * X_batch.mean(axis=0)\n",
    "                )\n",
    "            \n",
    "            # Normalize features\n",
    "            if self.feature_stats['std'].sum() > 0:\n",
    "                X_normalized = (X_batch - self.feature_stats['mean']) / (\n",
    "                    self.feature_stats['std'] + 1e-8\n",
    "                )\n",
    "            else:\n",
    "                X_normalized = X_batch\n",
    "            \n",
    "            # Update model\n",
    "            if self.training_samples == 0:\n",
    "                self.model.partial_fit(X_normalized, y_batch, classes=[0, 1])\n",
    "            else:\n",
    "                self.model.partial_fit(X_normalized, y_batch)\n",
    "            \n",
    "            self.training_samples += len(X_batch)\n",
    "            self.model_version += 1\n",
    "            \n",
    "            return {\n",
    "                'status': 'success',\n",
    "                'samples_processed': self.training_samples,\n",
    "                'version': self.model_version\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            # Error handling: Must gracefully handle mid-stream errors\n",
    "            print(f\"Error processing batch: {e}\")\n",
    "            return {'status': 'failed', 'error': str(e)}\n",
    "\n",
    "# Usage\n",
    "pipeline = OnlineLearningPipeline()\n",
    "for i in range(10):\n",
    "    X = np.random.rand(100, 20)\n",
    "    y = np.random.randint(0, 2, 100)\n",
    "    result = pipeline.process_stream(X, y)\n",
    "    print(f\"Batch {i}: {result}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. **Accuracy Variability** \ud83d\udcc9\n",
    "- May underfit compared to batch learning on same data\n",
    "- Sensitive to noisy mini-batches\n",
    "- Requires careful hyperparameter tuning\n",
    "- Risk of overfitting to recent noise\n",
    "- Order of data can affect final model (unlike batch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Online learning affected by data order\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "online_model1 = SGDClassifier(loss='log', random_state=42)\n",
    "online_model2 = SGDClassifier(loss='log', random_state=42)\n",
    "\n",
    "# Create synthetic data with trend\n",
    "X1_early = np.random.rand(500, 20)\n",
    "y1_early = (X1_early[:, 0] > 0.5).astype(int)\n",
    "\n",
    "X1_late = np.random.rand(500, 20)\n",
    "y1_late = (X1_late[:, 0] > 0.3).astype(int)  # Different rule!\n",
    "\n",
    "# Scenario 1: Easy data first, hard data later\n",
    "X1_ordered = np.vstack([X1_early, X1_late])\n",
    "y1_ordered = np.hstack([y1_early, y1_late])\n",
    "\n",
    "online_model1.fit(X1_ordered, y1_ordered)\n",
    "\n",
    "# Scenario 2: Hard data first, easy data later\n",
    "X2_ordered = np.vstack([X1_late, X1_early])\n",
    "y2_ordered = np.hstack([y1_late, y1_early])\n",
    "\n",
    "online_model2.fit(X2_ordered, y2_ordered)\n",
    "\n",
    "acc1 = online_model1.score(X1_late, y1_late)\n",
    "acc2 = online_model2.score(X1_late, y1_late)\n",
    "print(f\"Model 1 (easy\u2192hard) accuracy: {acc1:.4f}\")\n",
    "print(f\"Model 2 (hard\u2192easy) accuracy: {acc2:.4f}\")\n",
    "print(f\"Difference (order matters!): {abs(acc1-acc2):.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. **Data Dependency**\n",
    "- Performance heavily depends on data quality\n",
    "- If noisy data arrives, model learns noise\n",
    "- Continuous supply of data needed for good performance\n",
    "- Cannot recover from receiving bad data\n",
    "\n",
    "#### 4. **Hyperparameter Sensitivity** \ud83c\udfaf\n",
    "- Learning rate becomes critical\n",
    "- Batch size affects convergence\n",
    "- More difficult to tune than batch learning\n",
    "- Requires experimentation with streaming data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Learning rate impact on online learning\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "learning_rates = [0.001, 0.01, 0.1, 0.5, 1.0]\n",
    "accuracies = []\n",
    "\n",
    "for lr in learning_rates:\n",
    "    model = SGDClassifier(eta0=lr, learning_rate='constant', random_state=42)\n",
    "    \n",
    "    for i in range(100):\n",
    "        X = np.random.rand(100, 20)\n",
    "        y = np.random.randint(0, 2, 100)\n",
    "        \n",
    "        if i == 0:\n",
    "            model.partial_fit(X, y, classes=[0, 1])\n",
    "        else:\n",
    "            model.partial_fit(X, y)\n",
    "    \n",
    "    final_acc = model.score(X, y)\n",
    "    accuracies.append(final_acc)\n",
    "\n",
    "print(\"Learning Rate vs Final Accuracy:\")\n",
    "for lr, acc in zip(learning_rates, accuracies):\n",
    "    print(f\"  LR={lr}: {acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Online Learning Tools and Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# River: Modern library for online learning\n",
    "# Install: pip install river\n",
    "\n",
    "from river import linear_model, preprocessing, compose, metrics\n",
    "from sklearn.datasets import make_classification\n",
    "import numpy as np\n",
    "\n",
    "# Create online learning pipeline\n",
    "model = compose.Pipeline(\n",
    "    preprocessing.StandardScaler(),\n",
    "    linear_model.LogisticRegression()\n",
    ")\n",
    "\n",
    "# Stream data one sample at a time\n",
    "metric = metrics.Accuracy()\n",
    "\n",
    "X, y = make_classification(n_samples=1000, n_features=20, random_state=42)\n",
    "\n",
    "for i, (xi, yi) in enumerate(zip(X, y)):\n",
    "    # Make prediction on sample\n",
    "    y_pred = model.predict_one(xi)\n",
    "    \n",
    "    # Update metric\n",
    "    if y_pred is not None:\n",
    "        metric.update(yi, y_pred)\n",
    "    \n",
    "    # Learn from sample\n",
    "    model.learn_one(xi, yi)\n",
    "    \n",
    "    if i % 200 == 0:\n",
    "        print(f\"Sample {i}: Accuracy = {metric.get():.4f}\")\n",
    "\n",
    "print(f\"Final Accuracy: {metric.get():.4f}\")\n",
    "\n",
    "# Scikit-learn: partial_fit for online learning\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X_train = np.random.rand(10000, 20)\n",
    "y_train = np.random.randint(0, 2, 10000)\n",
    "\n",
    "model = SGDClassifier(loss='log', n_jobs=-1)\n",
    "\n",
    "# Train in mini-batches\n",
    "for batch_start in range(0, len(X_train), 100):\n",
    "    batch_end = min(batch_start + 100, len(X_train))\n",
    "    X_batch = X_train[batch_start:batch_end]\n",
    "    y_batch = y_train[batch_start:batch_end]\n",
    "    \n",
    "    if batch_start == 0:\n",
    "        model.partial_fit(X_batch, y_batch, classes=[0, 1])\n",
    "    else:\n",
    "        model.partial_fit(X_batch, y_batch)\n",
    "\n",
    "print(f\"Trained on {len(X_train)} samples using online learning\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}