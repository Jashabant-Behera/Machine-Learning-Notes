{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Batch vs Online Learning Comprehensive Comparison\n",
    "\n",
    "### Head-to-Head Comparison\n",
    "\n",
    "| Aspect | Batch Learning | Online Learning |\n",
    "|--------|---|---|\n",
    "| **Data Processing** | Entire dataset at once | One sample or mini-batch at a time |\n",
    "| **Training Phases** | Single large training phase | Continuous incremental updates |\n",
    "| **Memory Usage** | High (must load all data) | Low (only batch in memory) |\n",
    "| **Convergence Speed** | Slower overall | Faster per-sample |\n",
    "| **Adaptation to New Data** | Requires complete retraining | Immediate update |\n",
    "| **Real-time Capability** | Not suitable | Excellent |\n",
    "| **Computational Cost** | Very high initially | Spread over time |\n",
    "| **Model Stability** | Very stable | More sensitive to noise |\n",
    "| **Data Redundancy** | Handles poorly | Handles well |\n",
    "| **Implementation** | Simpler | More complex |\n",
    "| **Suitable Scale** | 1GB - 100GB datasets | 100GB+ or streaming |\n",
    "| **Tools** | Scikit-learn, Spark, TensorFlow | River, SKlearn (partial_fit) |\n",
    "| **Latency** | High gap between update | Low, real-time |\n",
    "| **Hyperparameter Tuning** | Easier to tune | Harder to tune |\n",
    "\n",
    "### Computational Complexity Comparison\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Batch Learning Complexity\n",
    "dataset_sizes = np.array([1000, 10000, 100000, 1000000])\n",
    "\n",
    "# Batch: O(n) where n = dataset size\n",
    "batch_time = dataset_sizes * 0.001  # Linear complexity\n",
    "\n",
    "# Online: O(1) per sample, so total = O(n) but with smaller constant\n",
    "# and can spread computation\n",
    "online_time_per_sample = 0.00001\n",
    "online_time_total = dataset_sizes * online_time_per_sample\n",
    "\n",
    "# Online with spread cost (can update model incrementally)\n",
    "online_time_amortized = dataset_sizes * 0.0001\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(dataset_sizes, batch_time, marker='o', label='Batch', linewidth=2)\n",
    "plt.plot(dataset_sizes, online_time_total, marker='s', label='Online (total)', linewidth=2)\n",
    "plt.xlabel('Dataset Size (samples)')\n",
    "plt.ylabel('Training Time (seconds)')\n",
    "plt.title('Training Time: Batch vs Online')\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Memory usage comparison\n",
    "plt.subplot(1, 2, 2)\n",
    "batch_memory = dataset_sizes / 1000 * 8  # 8 bytes per number\n",
    "online_memory = np.ones_like(dataset_sizes) * 0.008  # Fixed batch size\n",
    "\n",
    "plt.plot(dataset_sizes, batch_memory, marker='o', label='Batch', linewidth=2)\n",
    "plt.plot(dataset_sizes, online_memory, marker='s', label='Online', linewidth=2)\n",
    "plt.xlabel('Dataset Size (samples)')\n",
    "plt.ylabel('Peak Memory (GB)')\n",
    "plt.title('Memory Usage: Batch vs Online')\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Production Systems Comparison\n",
    "\n",
    "#### Batch Learning in Production\n",
    "```\n",
    "[Database] \u2192 [Batch Job Scheduled Daily]\n",
    "              \u2193 (1-2 hour process)\n",
    "           [Model Trained]\n",
    "              \u2193\n",
    "           [Save Model]\n",
    "              \u2193\n",
    "           [Deploy to Production]\n",
    "              \u2193\n",
    "       [Serve predictions all day]\n",
    "           (with same model)\n",
    "              \u2193\n",
    "           [Next day, repeat]\n",
    "```\n",
    "\n",
    "Example: Netflix Recommendation System\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch ML Pipeline\n",
    "from airflow import DAG\n",
    "from airflow.operators.python_operator import PythonOperator\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "default_args = {\n",
    "    'owner': 'data-team',\n",
    "    'start_date': datetime(2024, 1, 1),\n",
    "    'retries': 1\n",
    "}\n",
    "\n",
    "dag = DAG('daily_recommendation_model', default_args=default_args,\n",
    "          schedule_interval='0 2 * * *')  # Run at 2 AM daily\n",
    "\n",
    "# Task 1: Extract features from database\n",
    "def extract_data():\n",
    "    # Extract user-movie ratings, content features, etc.\n",
    "    pass\n",
    "\n",
    "# Task 2: Train model on all accumulated data\n",
    "def train_model():\n",
    "    # Train on millions of ratings\n",
    "    model = GradientBoostingRegressor(n_estimators=100)\n",
    "    model.fit(X_train, y_train)  # Takes 1-2 hours\n",
    "\n",
    "# Task 3: Evaluate and validate\n",
    "def validate_model():\n",
    "    # A/B test, quality checks\n",
    "    pass\n",
    "\n",
    "# Task 4: Deploy to production\n",
    "def deploy_model():\n",
    "    # Update serving infrastructure\n",
    "    pass\n",
    "\n",
    "t1 = PythonOperator(task_id='extract_data', python_callable=extract_data, dag=dag)\n",
    "t2 = PythonOperator(task_id='train_model', python_callable=train_model, dag=dag)\n",
    "t3 = PythonOperator(task_id='validate', python_callable=validate_model, dag=dag)\n",
    "t4 = PythonOperator(task_id='deploy', python_callable=deploy_model, dag=dag)\n",
    "\n",
    "t1 >> t2 >> t3 >> t4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Online Learning in Production\n",
    "```\n",
    "[Streaming Data Source (Kafka)]\n",
    "        \u2193 (Continuous)\n",
    "[Online ML Model]\n",
    "     (Continuously Updates)\n",
    "        \u2193\n",
    "[Real-time Predictions]\n",
    "```\n",
    "\n",
    "Example: Fraud Detection System\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Online ML Pipeline\n",
    "from river import linear_model, preprocessing, metrics\n",
    "from kafka import KafkaConsumer\n",
    "import json\n",
    "\n",
    "# Initialize online model\n",
    "model = preprocessing.StandardScaler() | linear_model.LogisticRegression()\n",
    "metric = metrics.Accuracy()\n",
    "\n",
    "# Connect to transaction stream\n",
    "consumer = KafkaConsumer(\n",
    "    'transactions',\n",
    "    bootstrap_servers=['localhost:9092'],\n",
    "    value_deserializer=lambda m: json.loads(m.decode('utf-8'))\n",
    ")\n",
    "\n",
    "print(\"Listening to transaction stream...\")\n",
    "\n",
    "for message in consumer:\n",
    "    transaction = message.value\n",
    "    \n",
    "    # Extract features\n",
    "    features = {\n",
    "        'amount': transaction['amount'],\n",
    "        'merchant_category': transaction['category'],\n",
    "        'time_of_day': transaction['hour'],\n",
    "        'user_history': transaction['user_avg_spend']\n",
    "    }\n",
    "    \n",
    "    # Predict: Is this fraud?\n",
    "    fraud_prob = model.predict_proba_one(features)\n",
    "    \n",
    "    if fraud_prob[True] > 0.8:  # High fraud probability\n",
    "        print(f\"\u26a0\ufe0f  FRAUD ALERT: {transaction['id']}\")\n",
    "        # Block transaction\n",
    "    \n",
    "    # Learn from ground truth (when available)\n",
    "    actual_fraud = transaction.get('confirmed_fraud', None)\n",
    "    if actual_fraud is not None:\n",
    "        model.learn_one(features, actual_fraud)\n",
    "        metric.update(actual_fraud, fraud_prob[True] > 0.5)\n",
    "    \n",
    "    # Log metric every 1000 transactions\n",
    "    if metric.n % 1000 == 0:\n",
    "        print(f\"Model accuracy: {metric.get():.4f} ({metric.n} samples)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Application Suitability\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch Learning Applications\n",
    "batch_applications = {\n",
    "    'recommendation_systems': 'Netflix, Amazon - retrain daily',\n",
    "    'fraud_detection': 'Batch daily training on past days data',\n",
    "    'price_prediction': 'Real estate, stock prices - weekly retraining',\n",
    "    'demand_forecasting': 'Retail, airlines - daily/weekly models',\n",
    "    'medical_imaging': 'CT scans, X-rays - trained on available cases'\n",
    "}\n",
    "\n",
    "# Online Learning Applications\n",
    "online_applications = {\n",
    "    'real_time_fraud_detection': 'Credit card - detect in milliseconds',\n",
    "    'streaming_analytics': 'Social media trends - continuous learning',\n",
    "    'adaptive_systems': 'Spam filters - learn new patterns immediately',\n",
    "    'autonomous_vehicles': 'Self-driving cars - adapt to road conditions',\n",
    "    'IoT_monitoring': 'Sensor data - continuous anomaly detection',\n",
    "    'recommendation': 'YouTube - learn user preference per click'\n",
    "}\n",
    "\n",
    "print(\"When to use Batch Learning:\")\n",
    "for app, desc in batch_applications.items():\n",
    "    print(f\"  \u2022 {app}: {desc}\")\n",
    "\n",
    "print(\"\\nWhen to use Online Learning:\")\n",
    "for app, desc in online_applications.items():\n",
    "    print(f\"  \u2022 {app}: {desc}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tools and Frameworks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch Learning Tools\n",
    "batch_tools = \"\"\"\n",
    "1. Scikit-learn\n",
    "   - Mature, stable, comprehensive algorithms\n",
    "   - Good for datasets that fit in memory\n",
    "   \n",
    "2. Apache Spark MLlib\n",
    "   - Distributed batch learning on clusters\n",
    "   - Handles terabyte-scale datasets\n",
    "   - For PySpark, use spark.mllib or spark.ml\n",
    "   \n",
    "3. TensorFlow/PyTorch\n",
    "   - Deep learning frameworks\n",
    "   - Can train on batches (not true online)\n",
    "   - Requires significant computational resources\n",
    "   \n",
    "4. XGBoost, LightGBM\n",
    "   - Gradient boosting frameworks\n",
    "   - Fast batch training\n",
    "   - Excellent for tabular data\n",
    "   \n",
    "5. H2O\n",
    "   - Distributed ML platform\n",
    "   - Auto ML capabilities\n",
    "   - Can handle large datasets\n",
    "\"\"\"\n",
    "\n",
    "# Online Learning Tools\n",
    "online_tools = \"\"\"\n",
    "1. River\n",
    "   - Modern Python library for online ML\n",
    "   - Supports classification, regression, clustering\n",
    "   - Stream learning and drift detection\n",
    "   - pip install river\n",
    "   \n",
    "2. Scikit-learn partial_fit\n",
    "   - Most sklearn models support partial_fit\n",
    "   - Can process mini-batches\n",
    "   - But not truly online (batch-like)\n",
    "   \n",
    "3. Kafka + Spark Streaming\n",
    "   - Real-time data pipelines\n",
    "   - Online updates with distributed computing\n",
    "   - Complex but powerful\n",
    "   \n",
    "4. Apache Flink\n",
    "   - Stream processing framework\n",
    "   - Real-time ML model updates\n",
    "   - Complex distributed system\n",
    "   \n",
    "5. Custom implementations\n",
    "   - Often needed for specific requirements\n",
    "   - Use SGDClassifier, SGDRegressor\n",
    "   - Implement online learning from scratch\n",
    "\"\"\"\n",
    "\n",
    "print(batch_tools)\n",
    "print(online_tools)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}